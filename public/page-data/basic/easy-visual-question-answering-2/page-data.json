{"componentChunkName":"component---src-templates-blog-post-blog-post-jsx","path":"/basic/easy-visual-question-answering-2/","result":{"data":{"post":{"id":"cG9zdDoyMDYx","excerpt":"<p>What is a Visual Question Answering? This problem is known as Visual Question Answering (VQA): answering open-ended questions about images. VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an [&hellip;]</p>\n","content":"<div class=\"nolwrap\"><h2 id=\"anchor1\">What is a Visual Question Answering?</h2>\n<p>This problem is known as Visual Question Answering (VQA): answering open-ended questions about images. VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image.</p>\n<blockquote><p>Keras is a simple-to-use but powerful deep learning <a href=\"/web-development/a-simple-explanation-of-the-bag-of-words-model-2/\">library for Python</a>. In this post, we’ll build a simple Recurrent Neural Network (RNN) and train it to solve a real problem with Keras.</p></blockquote>\n<p>This post is intended for complete <strong>beginners</strong> to Keras but does assume a basic background knowledge of RNNs. My introduction to Recurrent Neural Networks covers everything you need to know (and more) for this post – read that first if necessary.</p>\n<h3 id=\"anchor2\">How we can solve the problem?</h3>\n<p>This might seem like a pretty unapproachable problem at first, <strong>but in reality</strong> it’s probably more accessible than <em>you think</em>. In this post, we’ll explore basic methods for performing VQA and build our own simple implementation in Python. Here’s a demo of the final product of this post:</p>\n<ul>\n<li>Caveat: this post assumes a basic knowledge of Convolutional Neural Networks (CNNs);</li>\n<li>My introduction to CNNs covers everything you need to know, so start there if necessary.</li>\n</ul>\n<p>VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image.</p>\n<figure id=\"attachment_758\" aria-describedby=\"caption-attachment-758\" style=\"width: 300px\" class=\"wp-caption alignright\"><img src=\"/_gatsby/file/664b65158d0c28909d54883829ef200e/dsc03149.jpg?u=http%3A%2F%2Flocalhost%3A8888%2Fwp-content%2Fuploads%2F2008%2F06%2Fdsc03149.jpg\" alt=\"Yachtsody in Blue\" class=\"wp-image-758 size-medium inline-gatsby-image-wrapper\" data-reactroot=\"\"/><figcaption id=\"caption-attachment-758\" class=\"wp-caption-text\">Boats and reflections, Royal Perth Yacht Club</figcaption></figure>\n<p>We’ll also be using Keras, a deep learning library for Python, to power our model, so I recommend reviewing my introduction to Neural Networks with Keras if you’ve never seen Keras code before.</p>\n<h3 id=\"anchor3\">Creating a new environment for request</h3>\n<p>This problem is known as Visual Question Answering (VQA): answering open-ended questions about images. VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image.</p>\n<p>This problem is known as Visual Question Answering (VQA): answering open-ended questions about images. VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image.</p>\n<p>This problem is known as Visual Question Answering (VQA): answering open-ended questions about images. VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image.</p>\n<p>This problem is known as Visual Question Answering (VQA): answering open-ended questions about images. VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image.</p>\n<div id='gallery-1' class='gallery galleryid-2061 gallery-columns-3 gallery-size-full'><figure class='gallery-item'>\n\t\t\t<div class='gallery-icon landscape'>\n\t\t\t\t<img src=\"/_gatsby/file/aa1023fadffe32bf484f3d4c00cdf6b7/1_4UMe0F6rXeH-emJtQLkaSQ-scaled.jpeg?u=http%3A%2F%2Flocalhost%3A8888%2Fwp-content%2Fuploads%2F2022%2F10%2F1_4UMe0F6rXeH-emJtQLkaSQ-scaled.jpeg\" alt=\"\" class=\"attachment-full size-full inline-gatsby-image-wrapper\" data-reactroot=\"\"/>\n\t\t\t</div></figure><figure class='gallery-item'>\n\t\t\t<div class='gallery-icon landscape'>\n\t\t\t\t<img src=\"/_gatsby/file/3b912808c2b7e8e057202052635938ed/0_S7d5B2xFyg4GduDc-scaled.jpeg?u=http%3A%2F%2Flocalhost%3A8888%2Fwp-content%2Fuploads%2F2022%2F10%2F0_S7d5B2xFyg4GduDc-scaled.jpeg\" alt=\"\" class=\"attachment-full size-full inline-gatsby-image-wrapper\" data-reactroot=\"\"/>\n\t\t\t</div></figure><figure class='gallery-item'>\n\t\t\t<div class='gallery-icon landscape'>\n\t\t\t\t<img src=\"/_gatsby/file/1e36b26f42cfd561688e021fca6b86f2/1_9JaBfPmXYosuPFLF_SUppg.jpeg?u=http%3A%2F%2Flocalhost%3A8888%2Fwp-content%2Fuploads%2F2022%2F10%2F1_9JaBfPmXYosuPFLF_SUppg.jpeg\" alt=\"\" class=\"attachment-full size-full inline-gatsby-image-wrapper\" data-reactroot=\"\"/>\n\t\t\t</div></figure><figure class='gallery-item'>\n\t\t\t<div class='gallery-icon landscape'>\n\t\t\t\t<img src=\"/_gatsby/file/035ef5adcf4298806eef630644288862/0__PvzT5C6-x0LQ6Sv.jpeg?u=http%3A%2F%2Flocalhost%3A8888%2Fwp-content%2Fuploads%2F2022%2F10%2F0__PvzT5C6-x0LQ6Sv.jpeg\" alt=\"\" class=\"attachment-full size-full inline-gatsby-image-wrapper\" data-reactroot=\"\"/>\n\t\t\t</div></figure><figure class='gallery-item'>\n\t\t\t<div class='gallery-icon landscape'>\n\t\t\t\t<img src=\"/_gatsby/file/7b115613ef2a4b1353a8c3592ea78f56/0_iHdXHVEKyEvbkH_i-scaled.jpeg?u=http%3A%2F%2Flocalhost%3A8888%2Fwp-content%2Fuploads%2F2022%2F10%2F0_iHdXHVEKyEvbkH_i-scaled.jpeg\" alt=\"\" class=\"attachment-full size-full inline-gatsby-image-wrapper\" data-reactroot=\"\"/>\n\t\t\t</div></figure><figure class='gallery-item'>\n\t\t\t<div class='gallery-icon landscape'>\n\t\t\t\t<img src=\"/_gatsby/file/92df7889fe4de3e598e0adc92fe5fff1/1_l9eEF2o_Duwz92fyOFQIpQ-scaled.jpeg?u=http%3A%2F%2Flocalhost%3A8888%2Fwp-content%2Fuploads%2F2022%2F10%2F1_l9eEF2o_Duwz92fyOFQIpQ-scaled.jpeg\" alt=\"\" class=\"attachment-full size-full inline-gatsby-image-wrapper\" data-reactroot=\"\"/>\n\t\t\t</div></figure>\n\t\t</div>\n\n<p>This problem is known as Visual Question Answering (VQA): answering open-ended questions about images. VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image.</p>\n</div>","title":"Easy Visual Question Answering","date":"October 30, 2022","categories":{"nodes":[{"id":"dGVybTo5NjI=","uri":"/category/architecture/","name":"Architecture"},{"id":"dGVybTox","uri":"/category/basic/","name":"Basic"},{"id":"dGVybTo5NjU=","uri":"/category/education/","name":"Education"},{"id":"dGVybTo5NzA=","uri":"/category/templates/","name":"Templates"},{"id":"dGVybTo5Njg=","uri":"/category/time-management/","name":"Time management"},{"id":"dGVybTo4ODc=","uri":"/category/web-development/","name":"Web development"}]},"tags":{"nodes":[{"id":"dGVybTo5NDY=","uri":"/tag/discovery/","name":"Discovery"},{"id":"dGVybTo5NTI=","uri":"/tag/frameworks/","name":"Frameworks"},{"id":"dGVybTo5NDk=","uri":"/tag/optimization/","name":"Optimization"}]},"faq":{"faqItem":[{"question":"Question 1","answer":"<div class=\"nolwrap\"><p>Answer</p>\n</div>"},{"question":"Question 2","answer":"<div class=\"nolwrap\"><p>Answer</p>\n</div>"},{"question":"Question 3","answer":"<div class=\"nolwrap\"><p>Answer</p>\n</div>"},{"question":"ПРИВЕТ АНЯ","answer":"<div class=\"nolwrap\"><p>ПРИВЕТ</p>\n</div>"}]},"pageContext":{"pageContextItem":"<ol>\n<li><a href=\"#anchor1\">What is a Visual Question Answering?</a></li>\n<li><a href=\"#anchor2\">How we can solve the problem?</a></li>\n<li><a href=\"#anchor3\">Creating a new environment for request</a></li>\n</ol>\n"}},"previous":{"uri":"/web-development/a-simple-explanation-of-the-bag-of-words-model-2/","title":"A Simple Explanation of the Bag-of-Words Model"},"next":{"uri":"/web-development/an-introduction-to-recurrent-neural-networks-for-beginners/","title":"An Introduction to Recurrent Neural Networks for Beginners"}},"pageContext":{"id":"cG9zdDoyMDYx","previousPostId":"cG9zdDoyMDYw","nextPostId":"cG9zdDoyMDU1"}},"staticQueryHashes":["2157849609","3356497697","848497233"]}